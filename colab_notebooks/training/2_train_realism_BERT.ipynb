{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Discriminator BERT.ipynb","provenance":[{"file_id":"https://github.com/google-research/bert/blob/master/predicting_movie_reviews_with_bert_on_tf_hub.ipynb","timestamp":1575507721809}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"hsZvic2YxnTz","colab_type":"code","outputId":"aff4d8ac-e0ae-45c1-caaf-eebdeff4cc2b","executionInfo":{"status":"ok","timestamp":1576884296420,"user_tz":480,"elapsed":218211,"user":{"displayName":"Terise Cruven","photoUrl":"","userId":"00512573129192130578"}},"colab":{"base_uri":"https://localhost:8080/","height":392}},"source":["%tensorflow_version 1.x\n","import os\n","import tarfile\n","import shutil\n","\n","from sklearn.model_selection import train_test_split\n","import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","import tensorflow_hub as hub\n","from datetime import datetime\n","!pip install bert-tensorflow\n","!pip install -q gpt-2-simple\n","import gpt_2_simple as gpt2\n","import bert\n","from bert import run_classifier\n","from bert import optimization\n","from bert import tokenization\n","\n","tf.logging.set_verbosity(tf.logging.ERROR)\n","\n","OUTPUT_DIR = 'tmp'\n","\n","gpt2.mount_gdrive()\n","\n","gpt2.copy_file_from_gdrive(\"bert_gan_real.csv\")\n","\n","real = pd.read_csv('bert_gan_real.csv')\n","fakes = []\n","for i in [\"100\", \"200\", \"400\", \"600\", \"800\"]:\n","  gpt2.copy_file_from_gdrive(f\"bert_gan_fake{i}.csv\")\n","  fakes.append(pd.read_csv(f\"bert_gan_fake{i}.csv\"))\n","fake = pd.concat(fakes)\n","fake['reply']=fake['reply'].astype(str)\n","fake['real']=0\n","df = pd.concat([real,fake])[['comment','reply','real']].dropna()\n","\n","\n","INPUT_COLUMN = 'comment'\n","DATA_COLUMN = 'reply'\n","LABEL_COLUMN = 'real'\n","# label_list is the list of labels, i.e. True, False or 0, 1 or 'dog', 'cat'\n","label_list = [0, 1]\n","\n","train, test = train_test_split(df, test_size=0.1)\n","\n","# Use the InputExample class from BERT's run_classifier code to create examples from the data\n","train_InputExamples = train.apply(lambda x: bert.run_classifier.InputExample(guid=None, # Globally unique ID for bookkeeping, unused in this example\n","                                                                   text_a = x[INPUT_COLUMN], \n","                                                                   text_b = x[DATA_COLUMN], \n","                                                                   label = x[LABEL_COLUMN]), axis = 1)\n","\n","test_InputExamples = test.apply(lambda x: bert.run_classifier.InputExample(guid=None, \n","                                                                   text_a = x[INPUT_COLUMN], \n","                                                                   text_b = x[DATA_COLUMN], \n","                                                                   label = x[LABEL_COLUMN]), axis = 1)\n","\n","# This is a path to an uncased (all lowercase) version of BERT\n","BERT_MODEL_HUB = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\n","\n","def create_tokenizer_from_hub_module():\n","  \"\"\"Get the vocab file and casing info from the Hub module.\"\"\"\n","  with tf.Graph().as_default():\n","    bert_module = hub.Module(BERT_MODEL_HUB)\n","    tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n","    with tf.Session() as sess:\n","      vocab_file, do_lower_case = sess.run([tokenization_info[\"vocab_file\"],\n","                                            tokenization_info[\"do_lower_case\"]])\n","      \n","  return bert.tokenization.FullTokenizer(\n","      vocab_file=vocab_file, do_lower_case=do_lower_case)\n","\n","tokenizer = create_tokenizer_from_hub_module()\n","\n","# We'll set sequences to be at most 128 tokens long.\n","MAX_SEQ_LENGTH = 64\n","# Convert our train and test features to InputFeatures that BERT understands.\n","train_features = bert.run_classifier.convert_examples_to_features(train_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)\n","test_features = bert.run_classifier.convert_examples_to_features(test_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)\n","\n","def create_model(is_predicting, input_ids, input_mask, segment_ids, labels,\n","                 num_labels):\n","  \"\"\"Creates a classification model.\"\"\"\n","\n","  bert_module = hub.Module(\n","      BERT_MODEL_HUB,\n","      trainable=True)\n","  bert_inputs = dict(\n","      input_ids=input_ids,\n","      input_mask=input_mask,\n","      segment_ids=segment_ids)\n","  bert_outputs = bert_module(\n","      inputs=bert_inputs,\n","      signature=\"tokens\",\n","      as_dict=True)\n","\n","  # Use \"pooled_output\" for classification tasks on an entire sentence.\n","  # Use \"sequence_outputs\" for token-level output.\n","  output_layer = bert_outputs[\"pooled_output\"]\n","\n","  hidden_size = output_layer.shape[-1].value\n","\n","  # Create our own layer to tune for politeness data.\n","  output_weights = tf.get_variable(\n","      \"output_weights\", [num_labels, hidden_size],\n","      initializer=tf.truncated_normal_initializer(stddev=0.02))\n","\n","  output_bias = tf.get_variable(\n","      \"output_bias\", [num_labels], initializer=tf.zeros_initializer())\n","\n","  with tf.variable_scope(\"loss\"):\n","\n","    # Dropout helps prevent overfitting\n","    output_layer = tf.nn.dropout(output_layer, keep_prob=0.9)\n","\n","    logits = tf.matmul(output_layer, output_weights, transpose_b=True)\n","    logits = tf.nn.bias_add(logits, output_bias)\n","    log_probs = tf.nn.log_softmax(logits, axis=-1)\n","\n","    # Convert labels into one-hot encoding\n","    one_hot_labels = tf.one_hot(labels, depth=num_labels, dtype=tf.float32)\n","\n","    predicted_labels = tf.squeeze(tf.argmax(log_probs, axis=-1, output_type=tf.int32))\n","    # If we're predicting, we want predicted labels and the probabiltiies.\n","    if is_predicting:\n","      return (predicted_labels, log_probs)\n","\n","    # If we're train/eval, compute loss between predicted and actual label\n","    per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n","    loss = tf.reduce_mean(per_example_loss)\n","    return (loss, predicted_labels, log_probs)\n","\n","\n","# model_fn_builder actually creates our model function\n","# using the passed parameters for num_labels, learning_rate, etc.\n","def model_fn_builder(num_labels, learning_rate, num_train_steps,\n","                     num_warmup_steps):\n","  \"\"\"Returns `model_fn` closure for TPUEstimator.\"\"\"\n","  def model_fn(features, labels, mode, params):  # pylint: disable=unused-argument\n","    \"\"\"The `model_fn` for TPUEstimator.\"\"\"\n","\n","    input_ids = features[\"input_ids\"]\n","    input_mask = features[\"input_mask\"]\n","    segment_ids = features[\"segment_ids\"]\n","    label_ids = features[\"label_ids\"]\n","\n","    is_predicting = (mode == tf.estimator.ModeKeys.PREDICT)\n","    \n","    # TRAIN and EVAL\n","    if not is_predicting:\n","\n","      (loss, predicted_labels, log_probs) = create_model(\n","        is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n","\n","      train_op = bert.optimization.create_optimizer(\n","          loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu=False)\n","\n","      # Calculate evaluation metrics. \n","      def metric_fn(label_ids, predicted_labels):\n","        accuracy = tf.metrics.accuracy(label_ids, predicted_labels)\n","        f1_score = tf.contrib.metrics.f1_score(\n","            label_ids,\n","            predicted_labels)\n","        auc = tf.metrics.auc(\n","            label_ids,\n","            predicted_labels)\n","        recall = tf.metrics.recall(\n","            label_ids,\n","            predicted_labels)\n","        precision = tf.metrics.precision(\n","            label_ids,\n","            predicted_labels) \n","        true_pos = tf.metrics.true_positives(\n","            label_ids,\n","            predicted_labels)\n","        true_neg = tf.metrics.true_negatives(\n","            label_ids,\n","            predicted_labels)   \n","        false_pos = tf.metrics.false_positives(\n","            label_ids,\n","            predicted_labels)  \n","        false_neg = tf.metrics.false_negatives(\n","            label_ids,\n","            predicted_labels)\n","        return {\n","            \"eval_accuracy\": accuracy,\n","            \"f1_score\": f1_score,\n","            \"auc\": auc,\n","            \"precision\": precision,\n","            \"recall\": recall,\n","            \"true_positives\": true_pos,\n","            \"true_negatives\": true_neg,\n","            \"false_positives\": false_pos,\n","            \"false_negatives\": false_neg\n","        }\n","\n","      eval_metrics = metric_fn(label_ids, predicted_labels)\n","\n","      if mode == tf.estimator.ModeKeys.TRAIN:\n","        return tf.estimator.EstimatorSpec(mode=mode,\n","          loss=loss,\n","          train_op=train_op)\n","      else:\n","          return tf.estimator.EstimatorSpec(mode=mode,\n","            loss=loss,\n","            eval_metric_ops=eval_metrics)\n","    else:\n","      (predicted_labels, log_probs) = create_model(\n","        is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n","\n","      predictions = {\n","          'probabilities': log_probs,\n","          'labels': predicted_labels\n","      }\n","      return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n","\n","  # Return the actual model function in the closure\n","  return model_fn\n","\n","# Compute train and warmup steps from batch size\n","# These hyperparameters are copied from this colab notebook (https://colab.sandbox.google.com/github/tensorflow/tpu/blob/master/tools/colab/bert_finetuning_with_cloud_tpus.ipynb)\n","BATCH_SIZE = 32\n","LEARNING_RATE = 2e-5\n","NUM_TRAIN_EPOCHS = 3.0\n","# Warmup is a period of time where hte learning rate \n","# is small and gradually increases--usually helps training.\n","WARMUP_PROPORTION = 0.1\n","# Model configs\n","SAVE_CHECKPOINTS_STEPS = 500\n","SAVE_SUMMARY_STEPS = 100\n","\n","# Compute # train and warmup steps from batch size\n","num_train_steps = int(len(train_features) / BATCH_SIZE * NUM_TRAIN_EPOCHS)\n","num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)\n","\n","# Specify outpit directory and number of checkpoint steps to save\n","run_config = tf.estimator.RunConfig(\n","    model_dir=OUTPUT_DIR,\n","    save_summary_steps=SAVE_SUMMARY_STEPS,\n","    save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS)\n","\n","model_fn = model_fn_builder(\n","  num_labels=len(label_list),\n","  learning_rate=LEARNING_RATE,\n","  num_train_steps=num_train_steps,\n","  num_warmup_steps=num_warmup_steps)\n","\n","estimator = tf.estimator.Estimator(\n","  model_fn=model_fn,\n","  config=run_config,\n","  params={\"batch_size\": BATCH_SIZE})\n","\n","# Create an input function for training. drop_remainder = True for using TPUs.\n","train_input_fn = bert.run_classifier.input_fn_builder(\n","    features=train_features,\n","    seq_length=MAX_SEQ_LENGTH,\n","    is_training=True,\n","    drop_remainder=False)\n","\n","test_input_fn = run_classifier.input_fn_builder(\n","    features=test_features,\n","    seq_length=MAX_SEQ_LENGTH,\n","    is_training=False,\n","    drop_remainder=False)\n","\n","def getPrediction(in_sentence_pairs):\n","  labels = [\"Fake\", \"Real\"]\n","  input_examples = [run_classifier.InputExample(guid=\"\", text_a = x[0], text_b = x[1], label = 0) for x in in_sentence_pairs] # here, \"\" is just a dummy label\n","  input_features = run_classifier.convert_examples_to_features(input_examples, label_list, MAX_SEQ_LENGTH, tokenizer)\n","  predict_input_fn = run_classifier.input_fn_builder(features=input_features, seq_length=MAX_SEQ_LENGTH, is_training=False, drop_remainder=False)\n","  predictions = estimator.predict(predict_input_fn)\n","  return pd.DataFrame([(sentence[0], sentence[1], np.exp(prediction['probabilities'][1]), labels[prediction['labels']]) for sentence, prediction in zip(in_sentence_pairs, predictions)], columns=['comment', 'reply', 'prob_real','label'])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: bert-tensorflow in /usr/local/lib/python3.6/dist-packages (1.0.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from bert-tensorflow) (1.12.0)\n","WARNING:tensorflow:\n","The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","  * https://github.com/tensorflow/io (for I/O related ops)\n","If you depend on functionality not listed there, please file an issue.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:87: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:36: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n","of pandas will change to not sort by default.\n","\n","To accept the future behavior, pass 'sort=False'.\n","\n","To retain the current behavior and silence the warning, pass 'sort=True'.\n","\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"nucD4gluYJmK","colab_type":"code","outputId":"545f729d-9e0e-497d-d3a5-dedd03730da5","executionInfo":{"status":"ok","timestamp":1576886031965,"user_tz":480,"elapsed":520553,"user":{"displayName":"Terise Cruven","photoUrl":"","userId":"00512573129192130578"}},"colab":{"base_uri":"https://localhost:8080/","height":107}},"source":["print(f'Beginning Training!')\n","current_time = datetime.now()\n","estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n","print(\"Training took time \", datetime.now() - current_time)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Beginning Training!\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"],"name":"stderr"},{"output_type":"stream","text":["Training took time  0:08:40.117440\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"JIhejfpyJ8Bx","colab_type":"code","outputId":"cc5421f2-87aa-4cc4-c6dc-6a3eaad9a446","executionInfo":{"status":"ok","timestamp":1576886154167,"user_tz":480,"elapsed":45842,"user":{"displayName":"Terise Cruven","photoUrl":"","userId":"00512573129192130578"}},"colab":{"base_uri":"https://localhost:8080/","height":267}},"source":["estimator.evaluate(input_fn=test_input_fn, steps=None)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["{'auc': 0.99014676,\n"," 'eval_accuracy': 0.99841666,\n"," 'f1_score': 0.9991478,\n"," 'false_negatives': 2.0,\n"," 'false_positives': 15.0,\n"," 'global_step': 9059,\n"," 'loss': 0.008924643,\n"," 'precision': 0.9984971,\n"," 'recall': 0.9997994,\n"," 'true_negatives': 754.0,\n"," 'true_positives': 9966.0}"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"pB9ebq7SSvea","colab_type":"code","outputId":"4446b8e8-d019-4d61-da2e-4cf2d53a3108","executionInfo":{"status":"ok","timestamp":1576886253531,"user_tz":480,"elapsed":46522,"user":{"displayName":"Terise Cruven","photoUrl":"","userId":"00512573129192130578"}},"colab":{"base_uri":"https://localhost:8080/","height":406}},"source":["real_sent = test.loc[test['real']==1,['comment','reply']].values.tolist()\n","predictions_real = getPrediction(real_sent)\n","predictions_real.sort_values('prob_real')"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>comment</th>\n","      <th>reply</th>\n","      <th>prob_real</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1055</th>\n","      <td>Physicists are welcome to poach on biological ...</td>\n","      <td>&amp;gt;\"Why\" it evolved is not a useful question....</td>\n","      <td>0.000186</td>\n","      <td>Fake</td>\n","    </tr>\n","    <tr>\n","      <th>5771</th>\n","      <td>There's an episode of the original *Battlestar...</td>\n","      <td>https://www.imdb.com/title/tt0519755/</td>\n","      <td>0.061550</td>\n","      <td>Fake</td>\n","    </tr>\n","    <tr>\n","      <th>9177</th>\n","      <td>Yeah, but where can it be streamed? Its not on...</td>\n","      <td>[deleted]</td>\n","      <td>0.544600</td>\n","      <td>Real</td>\n","    </tr>\n","    <tr>\n","      <th>8042</th>\n","      <td>Remindme! 2 hours</td>\n","      <td>[deleted]</td>\n","      <td>0.623466</td>\n","      <td>Real</td>\n","    </tr>\n","    <tr>\n","      <th>8764</th>\n","      <td>Why would you expect larger batch sizes to red...</td>\n","      <td>[deleted]</td>\n","      <td>0.726553</td>\n","      <td>Real</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>8213</th>\n","      <td>The tutorial is json for me. Not sure if this ...</td>\n","      <td>It's a Jupyter notebook lol</td>\n","      <td>0.999986</td>\n","      <td>Real</td>\n","    </tr>\n","    <tr>\n","      <th>8491</th>\n","      <td>only have one monitor turned on while writing,...</td>\n","      <td>Phew, good thing I use Firefox</td>\n","      <td>0.999986</td>\n","      <td>Real</td>\n","    </tr>\n","    <tr>\n","      <th>7972</th>\n","      <td>Dont worry about the monsters at all.\\n\\n&amp;amp;...</td>\n","      <td>This. I once asked my brother, who’s an actor,...</td>\n","      <td>0.999986</td>\n","      <td>Real</td>\n","    </tr>\n","    <tr>\n","      <th>4730</th>\n","      <td>Jessica woke up in the morning and yawned and ...</td>\n","      <td>Until, she realised the sun was actually a poe...</td>\n","      <td>0.999986</td>\n","      <td>Real</td>\n","    </tr>\n","    <tr>\n","      <th>7077</th>\n","      <td>I think one of the two better deaths I've seen...</td>\n","      <td>Exactly this. Somebody has to live to tell the...</td>\n","      <td>0.999986</td>\n","      <td>Real</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>9968 rows × 4 columns</p>\n","</div>"],"text/plain":["                                                comment  ... label\n","1055  Physicists are welcome to poach on biological ...  ...  Fake\n","5771  There's an episode of the original *Battlestar...  ...  Fake\n","9177  Yeah, but where can it be streamed? Its not on...  ...  Real\n","8042                                  Remindme! 2 hours  ...  Real\n","8764  Why would you expect larger batch sizes to red...  ...  Real\n","...                                                 ...  ...   ...\n","8213  The tutorial is json for me. Not sure if this ...  ...  Real\n","8491  only have one monitor turned on while writing,...  ...  Real\n","7972  Dont worry about the monsters at all.\\n\\n&amp;...  ...  Real\n","4730  Jessica woke up in the morning and yawned and ...  ...  Real\n","7077  I think one of the two better deaths I've seen...  ...  Real\n","\n","[9968 rows x 4 columns]"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"v7wygcw8i5lm","colab_type":"code","outputId":"4ec7bd2c-7f37-458b-9d23-59c475e2b679","executionInfo":{"status":"ok","timestamp":1576886432791,"user_tz":480,"elapsed":6670,"user":{"displayName":"Terise Cruven","photoUrl":"","userId":"00512573129192130578"}},"colab":{"base_uri":"https://localhost:8080/","height":406}},"source":["gpt2.copy_file_from_gdrive(\"proposed_replies.csv\")\n","proposed_replies = pd.read_csv('proposed_replies.csv').dropna()\n","replies_to_test = proposed_replies[['comment','proposed_reply']].values.tolist()\n","predictions_proposed = getPrediction(replies_to_test)\n","predictions_proposed.sort_values('prob_real', ascending=False)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>comment</th>\n","      <th>reply</th>\n","      <th>prob_real</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>116</th>\n","      <td>\"They answered the question at the same time. ...</td>\n","      <td>This is a great post, thank you. Keep up the g...</td>\n","      <td>0.999974</td>\n","      <td>Real</td>\n","    </tr>\n","    <tr>\n","      <th>233</th>\n","      <td>I love using semi-colons; they're highly versa...</td>\n","      <td>I still use them for the same reason people us...</td>\n","      <td>0.999967</td>\n","      <td>Real</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>\"They blurted out opposite answers simultaneou...</td>\n","      <td>They were answering the same question.</td>\n","      <td>0.999959</td>\n","      <td>Real</td>\n","    </tr>\n","    <tr>\n","      <th>191</th>\n","      <td>When to use a semicolon: at the end of every s...</td>\n","      <td>The semicolon is like a semicolon in that it a...</td>\n","      <td>0.999926</td>\n","      <td>Real</td>\n","    </tr>\n","    <tr>\n","      <th>234</th>\n","      <td>I love using semi-colons; they're highly versa...</td>\n","      <td>I don't use them to separate two words, I use ...</td>\n","      <td>0.999908</td>\n","      <td>Real</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>61</th>\n","      <td>\"Yes,\" said Joe.\\n\\n\"No,\" said Jane at the sam...</td>\n","      <td>I'm not sure why you would want to read this. ...</td>\n","      <td>0.000078</td>\n","      <td>Fake</td>\n","    </tr>\n","    <tr>\n","      <th>253</th>\n","      <td>This is the end-all-be-all of writing. Just re...</td>\n","      <td>I've been meaning to do this for years.\\nIn fa...</td>\n","      <td>0.000078</td>\n","      <td>Fake</td>\n","    </tr>\n","    <tr>\n","      <th>254</th>\n","      <td>This is the end-all-be-all of writing. Just re...</td>\n","      <td>I don't think it is possible to follow these s...</td>\n","      <td>0.000076</td>\n","      <td>Fake</td>\n","    </tr>\n","    <tr>\n","      <th>215</th>\n","      <td>...man, I love me some semicolons. Once you fi...</td>\n","      <td>This is a great post. I hope I can contribute ...</td>\n","      <td>0.000074</td>\n","      <td>Fake</td>\n","    </tr>\n","    <tr>\n","      <th>46</th>\n","      <td>Just use an/some em dash(es). Bam.\\n\\n\"No you ...</td>\n","      <td>This is a great post. I hope I can contribute ...</td>\n","      <td>0.000072</td>\n","      <td>Fake</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>259 rows × 4 columns</p>\n","</div>"],"text/plain":["                                               comment  ... label\n","116  \"They answered the question at the same time. ...  ...  Real\n","233  I love using semi-colons; they're highly versa...  ...  Real\n","10   \"They blurted out opposite answers simultaneou...  ...  Real\n","191  When to use a semicolon: at the end of every s...  ...  Real\n","234  I love using semi-colons; they're highly versa...  ...  Real\n","..                                                 ...  ...   ...\n","61   \"Yes,\" said Joe.\\n\\n\"No,\" said Jane at the sam...  ...  Fake\n","253  This is the end-all-be-all of writing. Just re...  ...  Fake\n","254  This is the end-all-be-all of writing. Just re...  ...  Fake\n","215  ...man, I love me some semicolons. Once you fi...  ...  Fake\n","46   Just use an/some em dash(es). Bam.\\n\\n\"No you ...  ...  Fake\n","\n","[259 rows x 4 columns]"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"RO7BjuhOv9uW","colab_type":"code","colab":{}},"source":["best_predictions = predictions_proposed.sort_values('prob_real', ascending=False).groupby('comment').first().reset_index()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qXeAjAdSzfAo","colab_type":"code","colab":{}},"source":["return_table = proposed_replies.drop(['proposed_reply','Unnamed: 0'], axis=1).drop_duplicates().merge(best_predictions,on='comment')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8KqMAosc1Syc","colab_type":"code","colab":{}},"source":["return_table.loc[return_table['prob_real']>0.9].to_csv('realistic_replies.csv')\n","gpt2.copy_file_to_gdrive('realistic_replies.csv')\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wZd8SOOa4HBC","colab_type":"code","outputId":"71cd336b-1792-4aea-e23b-1cec37b6503e","executionInfo":{"status":"ok","timestamp":1576888568580,"user_tz":480,"elapsed":5715,"user":{"displayName":"Terise Cruven","photoUrl":"","userId":"00512573129192130578"}},"colab":{"base_uri":"https://localhost:8080/","height":356}},"source":["!pip install praw\n","import praw\n","reddit = praw.Reddit(client_id='kik3_XlQn0DcHQ', \n","                     client_secret='',\n","                     password='',\n","                     username='',\n","                     user_agent='')\n","subreddit = reddit.subreddit('writing')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Collecting praw\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f6/df/b42c0a3b86a43a62a46e5b2f07930230ac7719624800a2052218993fb767/praw-6.4.0-py2.py3-none-any.whl (126kB)\n","\u001b[K     |████████████████████████████████| 133kB 4.7MB/s \n","\u001b[?25hCollecting websocket-client>=0.54.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/19/44753eab1fdb50770ac69605527e8859468f3c0fd7dc5a76dd9c4dbd7906/websocket_client-0.56.0-py2.py3-none-any.whl (200kB)\n","\u001b[K     |████████████████████████████████| 204kB 13.3MB/s \n","\u001b[?25hCollecting prawcore<2.0,>=1.0.1\n","  Downloading https://files.pythonhosted.org/packages/76/b5/ce6282dea45cba6f08a30e25d18e0f3d33277e2c9fcbda75644b8dc0089b/prawcore-1.0.1-py2.py3-none-any.whl\n","Collecting update-checker>=0.16\n","  Downloading https://files.pythonhosted.org/packages/17/c9/ab11855af164d03be0ff4fddd4c46a5bd44799a9ecc1770e01a669c21168/update_checker-0.16-py2.py3-none-any.whl\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from websocket-client>=0.54.0->praw) (1.12.0)\n","Requirement already satisfied: requests<3.0,>=2.6.0 in /usr/local/lib/python3.6/dist-packages (from prawcore<2.0,>=1.0.1->praw) (2.21.0)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0,>=2.6.0->prawcore<2.0,>=1.0.1->praw) (3.0.4)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0,>=2.6.0->prawcore<2.0,>=1.0.1->praw) (1.24.3)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0,>=2.6.0->prawcore<2.0,>=1.0.1->praw) (2.8)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0,>=2.6.0->prawcore<2.0,>=1.0.1->praw) (2019.11.28)\n","Installing collected packages: websocket-client, prawcore, update-checker, praw\n","Successfully installed praw-6.4.0 prawcore-1.0.1 update-checker-0.16 websocket-client-0.56.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"eSULdDPq4iWC","colab_type":"code","colab":{}},"source":["for h in subreddit.rising(limit=5):\n","  already_replied = False\n","  for c in h.comments:\n","    if c.author == 'tupperware-party':\n","      already_replied = True\n","    for r in c.replies:\n","      if r.author == 'tupperware-party':\n","        already_replied = True\n","    if already_replied:\n","      break\n","  if already_replied:\n","    continue\n","  for c in h.comments:\n","    if c.score > 3:\n","      replies = generate_reply(c.body)\n","      reply_record.extend([(h.id, h.title, h.score, c.id, c.score, c.body, r) for r in replies])\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6uxlgsbXXXMs","colab_type":"code","outputId":"5317c6ef-dea9-4046-ad44-e941d5db9281","executionInfo":{"status":"ok","timestamp":1576874150368,"user_tz":480,"elapsed":115993,"user":{"displayName":"Terise Cruven","photoUrl":"","userId":"00512573129192130578"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# file_path = 'tuned_BERT_discriminator.tar'\n","\n","# with tarfile.open(file_path, 'w') as tar:\n","#     tar.add(OUTPUT_DIR)\n","\n","# shutil.copyfile(file_path, \"/content/drive/My Drive/\" + file_path)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/drive/My Drive/tuned_BERT_discriminator.tar'"]},"metadata":{"tags":[]},"execution_count":10}]}]}
